# AI notes

> 范围：
>
> 人工智能 {机器学习 {监督学习，无监督学习，强化学习}}
>
> p.s. 监督学习（分类、回归）和无监督学习（聚合、降维）含有：深度学习
>
> p.s. 强化学习含有：深度强化学习

#### 1. 监督学习

分类学习：分类问题中，输出是离散的，可以说是离散变量预测，定性输出称为分类

回归学习：回归问题中，输出是连续的，可以说是连续变量预测，定量输出称为回归



##### 1.1 分类学习

###### 1.1.1 朴素贝叶斯

(Navie Bayes)

- 朴素贝叶斯属于生成模型

- 朴素贝叶斯存在条件独立性假设，即对于模型中的每个条件来说，他们发生的概率都是相互独立的，因此主要缺点是，不能学习特征间的相互作用

- 当某个特征出现的概率为0时，将会出现某个类别的概率为0，这是不符合概率规律的，因此朴素贝叶斯需要加入smoothing平滑，分别有Epsilon平滑和Laplace平滑
- Epsilon平滑：计算时将所有为0的概率附上一个极小的值
- Laplace平滑：引入一个alpha系数，在计算分母时 +M*alpha，M为该特征的类型数量；在计算分子时+alpha
- 朴素贝叶斯的优点是训练的速度较快，仅仅只是特征概率的数学运算；对缺失数据不太敏感，通常用于文本分类；朴素贝叶斯对结果解释容易理解
- 缺点是对输入数据的表达形式很敏感；且当样本特征有关联时，分类效果不好



###### 1.1.2 K近邻

(K-Nearest Neighbor)



###### 1.1.3 决策树

(Decision Tree)



###### 1.1.4 随机森林

(Random Forest)



###### 1.1.5 支持向量机

(SVM)



##### 1.2 回归学习

###### 1.2.1 逻辑回归

(Logistic Regression)



###### 1.2.2 支持向量回归



###### 1.2.3 K近邻



#### 2. 无监督学习



#### 3. 深度学习

##### 3.1 多层感知机

pass



##### 3.2 卷积神经网络

pass



##### 3.3 循环神经网络

pass



##### 3.4 长短时记忆网络

pass



##### 3.5 Traansformer神经网络

pass



##### 3.6 Bert预训练模型

pass



